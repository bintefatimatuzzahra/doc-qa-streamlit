{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNnlmpVx6k6HVcxUlsTl0c2"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Final Cleaned Up code"],"metadata":{"id":"YofzI5Xhhbru"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uM6ZQ25Kj5v-","executionInfo":{"status":"ok","timestamp":1734287962726,"user_tz":-300,"elapsed":30764,"user":{"displayName":"Binte Fatima Tuz Zahra","userId":"16463446727988883636"}},"outputId":"7b7fac14-ec2e-438f-f523-e7cb59758e33"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["!pip install -r /content/drive/MyDrive/bintefatimatuzzahra28/ML_Project/requirements.txt -q"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Tqmf2BsEkDeO","executionInfo":{"status":"ok","timestamp":1734288027209,"user_tz":-300,"elapsed":60992,"user":{"displayName":"Binte Fatima Tuz Zahra","userId":"16463446727988883636"}},"outputId":"6de24383-a69d-468f-a424-ea783ad52f64"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/981.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m972.8/981.5 kB\u001b[0m \u001b[31m44.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.4/149.4 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.0/209.0 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.5/27.5 MB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m390.3/390.3 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.4/48.4 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m52.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.4/90.4 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m411.2/411.2 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m60.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m249.9/249.9 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.8/131.8 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.9/434.9 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m49.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m64.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.3/244.3 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m472.8/472.8 kB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.5/112.5 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m586.9/586.9 kB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m514.6/514.6 kB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m53.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m50.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.0/298.0 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m274.9/274.9 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m55.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.9/62.9 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.9/159.9 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.2/19.2 MB\u001b[0m \u001b[31m72.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.6/114.6 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.2/59.2 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m94.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m76.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}]},{"cell_type":"code","source":["import getpass\n","import os\n","\n","if not os.getenv(\"COHERE_API_KEY\"):\n","    os.environ[\"COHERE_API_KEY\"] = getpass.getpass(\"Enter your Cohere API key: \")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wJlXjR4gkHGc","executionInfo":{"status":"ok","timestamp":1734288048076,"user_tz":-300,"elapsed":11791,"user":{"displayName":"Binte Fatima Tuz Zahra","userId":"16463446727988883636"}},"outputId":"ff90ad56-b800-4a54-8775-28834f2d89b5"},"execution_count":3,"outputs":[{"name":"stdout","output_type":"stream","text":["Enter your Cohere API key: ··········\n"]}]},{"cell_type":"code","source":["import getpass\n","import os\n","\n","if not os.getenv(\"GoogleVertex_API_KEY\"):\n","    os.environ[\"GoogleVertex_API_KEY\"] = getpass.getpass(\"Enter your Google Vertex API key: \")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ifra_5s4kIA2","executionInfo":{"status":"ok","timestamp":1734288056986,"user_tz":-300,"elapsed":4132,"user":{"displayName":"Binte Fatima Tuz Zahra","userId":"16463446727988883636"}},"outputId":"1c79073b-649f-487f-de85-358af08a719e"},"execution_count":4,"outputs":[{"name":"stdout","output_type":"stream","text":["Enter your Google Vertex API key: ··········\n"]}]},{"cell_type":"code","source":["os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/content/drive/MyDrive/bintefatimatuzzahra28/ML_Project/mymlproject-444721-140c4261cfb8.json\""],"metadata":{"id":"33XYiOWGkKvw","executionInfo":{"status":"ok","timestamp":1734288062150,"user_tz":-300,"elapsed":349,"user":{"displayName":"Binte Fatima Tuz Zahra","userId":"16463446727988883636"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["import os\n","import json\n","import numpy as np\n","import faiss\n","import streamlit as st\n","from langchain.document_loaders import PyPDFLoader, TextLoader\n","from tempfile import NamedTemporaryFile\n","from langchain.text_splitter import RecursiveCharacterTextSplitter\n","from langchain_cohere import CohereEmbeddings\n","from langchain.prompts import PromptTemplate\n","from langchain.chains import LLMChain\n","from langchain_google_vertexai import ChatVertexAI\n","from tenacity import retry, stop_after_attempt, wait_exponential\n","from pyngrok import ngrok\n","\n","ngrok.set_auth_token(\"2po1TCRu94I8GFTrAfJ4wkhmbKj_7CkEpn4edG2oAWV2t9zQa\")\n","\n","# Token estimation function\n","def estimate_tokens(text):\n","    words = text.split()\n","    return int(len(words) / 0.75)  # Rough token estimate per document\n","\n","\n","# Process Uploaded Files\n","def process_uploaded_files(uploaded_files):\n","    \"\"\"Process and load documents from uploaded files.\"\"\"\n","    document_list = []\n","    for uploaded_file in uploaded_files:\n","        # Save the uploaded file to a temporary file\n","        file_extension = os.path.splitext(uploaded_file.name)[1].lower()\n","\n","        with NamedTemporaryFile(delete=False, suffix=file_extension) as tmp_file:\n","            tmp_file.write(uploaded_file.getvalue())\n","            temp_file_path = tmp_file.name\n","\n","        # Choose loader based on file type\n","        if file_extension == \".pdf\":\n","            loader = PyPDFLoader(temp_file_path)\n","        elif file_extension == \".txt\":\n","            loader = TextLoader(temp_file_path, encoding=\"utf-8\")  # Use UTF-8 encoding for text files\n","        else:\n","            st.warning(f\"Unsupported file format: {file_extension}. Skipping {uploaded_file.name}\")\n","            continue\n","\n","        # Load documents and extend the document list\n","        try:\n","            documents = loader.load()\n","            document_list.extend(documents)\n","        except Exception as e:\n","            st.error(f\"Error loading {uploaded_file.name}: {e}\")\n","            continue\n","\n","        # Optionally clean up the temporary file after processing\n","        os.remove(temp_file_path)\n","\n","    return document_list\n","\n","\n","# Split Documents into Chunks\n","def split_docs(documents, chunk_size=1000, chunk_overlap=20, max_tokens=2000):\n","    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n","    chunks = text_splitter.split_documents(documents)\n","\n","    # Ensure chunks do not exceed token limit\n","    valid_chunks = []\n","    for chunk in chunks:\n","        token_count = estimate_tokens(chunk.page_content)\n","        if token_count <= max_tokens:\n","            valid_chunks.append(chunk)\n","        else:\n","            st.warning(f\"Skipping chunk due to token limit: {chunk.page_content[:100]}... (tokens: {token_count})\")\n","\n","    return valid_chunks\n","\n","\n","# Create the Cohere Embedding Model\n","embeddings = CohereEmbeddings(model=\"embed-english-v3.0\")\n","\n","\n","# Implement Retry Logic for Embeddings\n","@retry(stop=stop_after_attempt(5), wait=wait_exponential(min=1, max=10))\n","def embed_documents_with_retry(texts, embeddings):\n","    return embeddings.embed_documents(texts)\n","\n","\n","# Create FAISS Vectorstore from Docs\n","def create_faiss_vectorstore_from_docs(docs, embeddings, faiss_index_path, metadata_path):\n","    texts = [doc.page_content for doc in docs]\n","\n","    # Batch embedding to prevent rate limit issues\n","    embeddings_matrix = []\n","    batch_size = 100  # Adjust based on rate limit\n","    for i in range(0, len(texts), batch_size):\n","        batch = texts[i:i + batch_size]\n","        embeddings_matrix.extend(embed_documents_with_retry(batch, embeddings))\n","\n","    embeddings_array = np.array(embeddings_matrix).astype('float32')\n","    dimension = embeddings_array.shape[1]\n","    index = faiss.IndexFlatL2(dimension)\n","    index.add(embeddings_array)\n","\n","    # Overwrite FAISS index if it exists\n","    if os.path.exists(faiss_index_path):\n","        os.remove(faiss_index_path)\n","    faiss.write_index(index, faiss_index_path)\n","\n","    # Save updated metadata\n","    metadata = [{'doc_id': i, 'content': doc.page_content} for i, doc in enumerate(docs)]\n","    with open(metadata_path, 'w') as f:\n","        json.dump(metadata, f)\n","\n","    return index\n","\n","\n","# Perform Retrieval and Generate Answer\n","def search_similar_docs_with_faiss_and_generate_answer(query, index, metadata, embeddings, model, k=3, max_context_tokens=2000):\n","    \"\"\"Retrieve and synthesize information from multiple documents.\"\"\"\n","    query_embedding = embeddings.embed_query(query)\n","    query_embedding = np.array(query_embedding).astype('float32').reshape(1, -1)\n","\n","    # Perform FAISS search\n","    _, indices = index.search(query_embedding, k)\n","\n","    if indices[0].size > 0 and np.any(indices[0] != -1):  # Ensure valid retrieval\n","        retrieved_docs = [metadata[i] for i in indices[0] if i != -1]\n","        st.write(f\"Retrieved {len(retrieved_docs)} document(s) for the query:\")\n","        #for i, doc in enumerate(retrieved_docs):                                   #for turning on data retrieval\n","        #    st.write(f\"Document {i+1} Snippet: {doc['content'][:200]}...\")  # Display snippet\n","\n","        # Concatenate context for the LLM\n","        context = \"\\n---\\n\".join([f\"Document {i+1}:\\n{doc['content']}\" for i, doc in enumerate(retrieved_docs)])\n","\n","        # Summarize context if it exceeds token limit\n","        if len(context.split()) > max_context_tokens:\n","            st.write(\"Context too large; summarizing...\")\n","            context = summarize_long_context(retrieved_docs, model, max_context_tokens)\n","\n","        if not context.strip():\n","            st.write(\"No sufficient context retrieved to answer the query.\")\n","            return \"I cannot determine this from the provided information.\"\n","\n","        # Generate the answer\n","        #st.write(f\"Context passed to LLM: {context[:500]}...\")  # Display first 500 chars for debugging\n","        answer = generate_answer_with_llm(query, retrieved_docs, model)\n","        st.write(f\"### Generated Answer: {answer}\")\n","    else:\n","        st.write(\"No relevant documents found for the query.\")\n","        return \"I cannot determine this from the provided information.\"\n","\n","\n","\n","# Generate Answer Using LLM\n","def generate_answer_with_llm(query, retrieved_docs, model):\n","    context = \"\\n---\\n\".join([f\"Document {i+1}:\\n{doc['content']}\" for i, doc in enumerate(retrieved_docs)])\n","\n","    prompt = PromptTemplate(\n","        input_variables=[\"question\", \"context\"],\n","        template=\"\"\"You are a helpful and advanced assistant designed to process information from provided documents and you can reason across multiple documents.\n","                    Your task is to answer the question based on the provided documents. If the answer cannot be determined from the documents, respond with \"I cannot determine this from the provided information.\"\n","\n","        Context:\n","        {context}\n","\n","        Question:\n","        {question}\n","\n","        Answer:\"\"\"\n","    )\n","\n","    llm_chain = LLMChain(prompt=prompt, llm=model)\n","    answer = llm_chain.run({\"question\": query, \"context\": context})\n","    return answer\n","\n","\n","# Summarize Long Context to Fit Token Limit\n","def summarize_long_context(retrieved_docs, model, max_context_tokens=2000):\n","    \"\"\"Summarize documents to fit within the token limit.\"\"\"\n","    summaries = []\n","    prompt = PromptTemplate(\n","        input_variables=[\"content\"],\n","        template=\"\"\"Summarize the following document to capture the key points in 200 words or less:\n","\n","        {content}\n","\n","        Summary:\"\"\"\n","    )\n","\n","    llm_chain = LLMChain(prompt=prompt, llm=model)\n","\n","    for doc in retrieved_docs:\n","        summary = llm_chain.run({\"content\": doc['content']})\n","        summaries.append(summary.strip())\n","\n","    # Combine summaries, ensuring they fit within the token limit\n","    combined_summary = \"\\n---\\n\".join(summaries)\n","    return combined_summary[:max_context_tokens]\n","\n","# Process Uploaded Files and Update FAISS Index\n","def update_index_with_new_files(uploaded_files, faiss_index_path, metadata_path, embeddings):\n","    if uploaded_files:\n","        # Process newly uploaded documents\n","        new_docs = process_uploaded_files(uploaded_files)\n","        new_docs = split_docs(new_docs, chunk_size=1000, chunk_overlap=20, max_tokens=2000)\n","\n","        if new_docs:\n","            # Load existing index and metadata if they exist\n","            if os.path.exists(faiss_index_path) and os.path.exists(metadata_path):\n","                st.write(\"Updating existing FAISS index...\")\n","                existing_index = faiss.read_index(faiss_index_path)\n","                with open(metadata_path, 'r') as f:\n","                    existing_metadata = json.load(f)\n","            else:\n","                st.write(\"Creating a new FAISS index...\")\n","                existing_index = None\n","                existing_metadata = []\n","\n","            # Embed new documents\n","            new_texts = [doc.page_content for doc in new_docs]\n","            new_embeddings = []\n","            for i in range(0, len(new_texts), 100):  # Batch embedding\n","                batch = new_texts[i:i + 100]\n","                new_embeddings.extend(embed_documents_with_retry(batch, embeddings))\n","\n","            new_embeddings_array = np.array(new_embeddings).astype('float32')\n","\n","            # Create or update FAISS index\n","            if existing_index:\n","                existing_index.add(new_embeddings_array)\n","                metadata = existing_metadata + [{'doc_id': len(existing_metadata) + i, 'content': doc.page_content}\n","                                                 for i, doc in enumerate(new_docs)]\n","            else:\n","                dimension = new_embeddings_array.shape[1]\n","                existing_index = faiss.IndexFlatL2(dimension)\n","                existing_index.add(new_embeddings_array)\n","                metadata = [{'doc_id': i, 'content': doc.page_content} for i, doc in enumerate(new_docs)]\n","\n","            # Save the updated FAISS index and metadata\n","            faiss.write_index(existing_index, faiss_index_path)\n","            with open(metadata_path, 'w') as f:\n","                json.dump(metadata, f)\n","\n","            return existing_index, metadata\n","    return None, None\n","\n","\n","# Load FAISS Index and Metadata\n","def load_faiss_index(faiss_index_path):\n","    try:\n","        index = faiss.read_index(faiss_index_path)\n","        return index\n","    except Exception as e:\n","        st.write(f\"Error loading FAISS index: {e}\")\n","        return None\n","\n","def load_metadata(metadata_path):\n","    try:\n","        with open(metadata_path, 'r') as f:\n","            metadata = json.load(f)\n","        return metadata\n","    except Exception as e:\n","        st.write(f\"Error loading metadata: {e}\")\n","        return []\n","\n","\n","# Main Streamlit Interface\n","def main():\n","    st.title(\"Document-based Question Answering System\")\n","\n","    # Upload Documents\n","    uploaded_files = st.file_uploader(\n","        \"Upload your documents (.pdf or .txt):\",\n","        type=[\"pdf\", \"txt\"],\n","        accept_multiple_files=True,\n","    )\n","\n","    # FAISS index and metadata paths (hidden)\n","    faiss_index_path = \"/content/drive/MyDrive/bintefatimatuzzahra28/ML_Project/faiss_metadata/faiss_index.index\"\n","    metadata_path = \"/content/drive/MyDrive/bintefatimatuzzahra28/ML_Project/faiss_metadata/metadata.json\"\n","\n","    # Initialize Vertex AI model\n","    model = ChatVertexAI(model=\"gemini-1.5-flash\", project_id=\"mymlproject-444721\")\n","\n","    # Check if FAISS index exists and load or create\n","    if os.path.exists(faiss_index_path) and os.path.exists(metadata_path):\n","        st.write(\"FAISS index exists. Loading FAISS index...\")\n","        metadata = load_metadata(metadata_path)\n","        index = load_faiss_index(faiss_index_path)\n","    else:\n","        st.write(\"No FAISS index found. Please upload documents to create the index.\")\n","        metadata, index = None, None\n","\n","    # Update FAISS index and metadata if new files are uploaded\n","    new_index, new_metadata = update_index_with_new_files(\n","        uploaded_files, faiss_index_path, metadata_path, embeddings\n","    )\n","    if new_index and new_metadata:\n","        index = new_index\n","        metadata = new_metadata\n","\n","    # Query System\n","    query = st.text_input(\"Enter your question:\")\n","\n","    if query:\n","        if index and metadata:\n","            search_similar_docs_with_faiss_and_generate_answer(query, index, metadata, embeddings, model)\n","        else:\n","            st.write(\"No documents available for querying. Please upload files.\")\n","\n","if __name__ == \"__main__\":\n","    main()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B7iaQzvgj3G-","executionInfo":{"status":"ok","timestamp":1734288094415,"user_tz":-300,"elapsed":19564,"user":{"displayName":"Binte Fatima Tuz Zahra","userId":"16463446727988883636"}},"outputId":"5a928d35-72ef-4cc6-87b5-b7bb60299ad2"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":[]},{"output_type":"stream","name":"stderr","text":["2024-12-15 18:41:28.663 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n","2024-12-15 18:41:29.065 \n","  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n","  command:\n","\n","    streamlit run /usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py [ARGUMENTS]\n","2024-12-15 18:41:29.066 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n","2024-12-15 18:41:29.069 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n","2024-12-15 18:41:29.071 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n","2024-12-15 18:41:29.074 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n","2024-12-15 18:41:29.076 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n","2024-12-15 18:41:29.078 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n","2024-12-15 18:41:29.547 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n","2024-12-15 18:41:29.549 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n","2024-12-15 18:41:29.554 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n","2024-12-15 18:41:29.555 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n","2024-12-15 18:41:31.846 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n","2024-12-15 18:41:31.848 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n","2024-12-15 18:41:31.850 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n","2024-12-15 18:41:31.851 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n","2024-12-15 18:41:31.852 Session state does not function when running a script without `streamlit run`\n","2024-12-15 18:41:31.854 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n","2024-12-15 18:41:31.855 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"]}]},{"cell_type":"code","source":["%cd \"/content/drive/MyDrive/bintefatimatuzzahra28/ML_Project/\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DAgbp8uBkZ-r","executionInfo":{"status":"ok","timestamp":1734288825306,"user_tz":-300,"elapsed":376,"user":{"displayName":"Binte Fatima Tuz Zahra","userId":"16463446727988883636"}},"outputId":"81fbf272-1418-4b03-9caf-8dfd610e3ce8"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/bintefatimatuzzahra28/ML_Project\n"]}]},{"cell_type":"code","source":["from pyngrok import ngrok\n","\n","# Start Streamlit in the background\n","!streamlit run finalcode.py &>/dev/null &\n","#!streamlit run txtloader_w_new_prompt.py &>/dev/null &\n","#!streamlit run New_w_txtloader.py &>/dev/null &\n","#!streamlit run metadata_faiss_index_fixed_wsettingsapply.py &>/dev/null &\n","#!streamlit run app.py &>/dev/null &\n","#!streamlit run app.py\n","\n","# Set up an ngrok tunnel to the Streamlit app\n","public_url = ngrok.connect(8501)\n","print(f\"Streamlit app is live at: {public_url}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d5_EzLkukc5V","executionInfo":{"status":"ok","timestamp":1734288829078,"user_tz":-300,"elapsed":785,"user":{"displayName":"Binte Fatima Tuz Zahra","userId":"16463446727988883636"}},"outputId":"b24a35cb-ed57-4f76-f927-f6c860519120"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Streamlit app is live at: NgrokTunnel: \"https://94f4-34-125-96-178.ngrok-free.app\" -> \"http://localhost:8501\"\n"]}]},{"cell_type":"code","source":["!lsof -i:8501"],"metadata":{"id":"_KLQuFMnkdt4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!kill -9 7620"],"metadata":{"id":"E3gf_432kgxT"},"execution_count":null,"outputs":[]}]}